import configparser
import os
import pytest
from pathlib import Path


class TestPytestConfiguration:
    """Test suite for pytest.ini configuration validation."""
    
    @pytest.fixture
    def config_file_path(self):
        """Return the path to pytest.ini file."""
        return Path(__file__).parent / "pytest.ini"
    
    @pytest.fixture
    def config(self, config_file_path):
        """Load and return pytest configuration."""
        if not config_file_path.exists():
            pytest.skip(f"pytest.ini not found at {config_file_path}")
        
        config = configparser.ConfigParser()
        config.read(config_file_path)
        return config
    
    def test_config_file_exists(self, config_file_path):
        """Test that pytest.ini file exists."""
        assert config_file_path.exists(), "pytest.ini file should exist"
    
    def test_tool_pytest_section_exists(self, config):
        """Test that [tool:pytest] section exists."""
        assert "tool:pytest" in config.sections(), "Missing [tool:pytest] section"
    
    def test_testpaths_configuration(self, config):
        """Test testpaths setting."""
        section = config["tool:pytest"]
        assert "testpaths" in section, "testpaths should be configured"
        assert section["testpaths"] == "tests", "testpaths should point to 'tests' directory"
    
    def test_python_files_patterns(self, config):
        """Test python_files patterns."""
        section = config["tool:pytest"]
        assert "python_files" in section, "python_files should be configured"
        
        patterns = section["python_files"].split()
        expected_patterns = ["test_*.py", "*_test.py"]
        assert patterns == expected_patterns, f"Expected {expected_patterns}, got {patterns}"
    
    def test_python_classes_pattern(self, config):
        """Test python_classes pattern."""
        section = config["tool:pytest"]
        assert "python_classes" in section, "python_classes should be configured"
        assert section["python_classes"] == "Test*", "python_classes should be 'Test*'"
    
    def test_python_functions_pattern(self, config):
        """Test python_functions pattern."""
        section = config["tool:pytest"]
        assert "python_functions" in section, "python_functions should be configured"
        assert section["python_functions"] == "test_*", "python_functions should be 'test_*'"
    
    def test_addopts_configuration(self, config):
        """Test addopts settings."""
        section = config["tool:pytest"]
        assert "addopts" in section, "addopts should be configured"
        
        addopts = section["addopts"].split()
        expected_opts = [
            "-v", "--strict-markers", "--strict-config", "--tb=short",
            "--cov=src", "--cov-report=term-missing", "--cov-report=html:htmlcov",
            "--cov-fail-under=80", "--durations=10", "--maxfail=3"
        ]
        
        for opt in expected_opts:
            assert opt in addopts, f"Missing option: {opt}"
    
    def test_coverage_settings(self, config):
        """Test coverage-related settings in addopts."""
        section = config["tool:pytest"]
        addopts = section["addopts"]
        
        assert "--cov=src" in addopts, "Coverage should be enabled for src directory"
        assert "--cov-report=term-missing" in addopts, "Terminal coverage report should be enabled"
        assert "--cov-report=html:htmlcov" in addopts, "HTML coverage report should be configured"
        assert "--cov-fail-under=80" in addopts, "Coverage threshold should be set to 80%"
    
    def test_strict_settings(self, config):
        """Test strict configuration settings."""
        section = config["tool:pytest"]
        addopts = section["addopts"]
        
        assert "--strict-markers" in addopts, "Strict markers should be enabled"
        assert "--strict-config" in addopts, "Strict config should be enabled"
    
    def test_output_settings(self, config):
        """Test output and display settings."""
        section = config["tool:pytest"]
        addopts = section["addopts"]
        
        assert "-v" in addopts, "Verbose output should be enabled"
        assert "--tb=short" in addopts, "Short traceback format should be configured"
        assert "--durations=10" in addopts, "Duration reporting should be enabled"
        assert "--maxfail=3" in addopts, "Max failures should be limited to 3"
    
    def test_markers_configuration(self, config):
        """Test markers configuration."""
        section = config["tool:pytest"]
        assert "markers" in section, "markers should be configured"
        
        markers_text = section["markers"]
        expected_markers = [
            "unit: Unit tests",
            "integration: Integration tests", 
            "database: Database tests",
            "slow: Slow running tests",
            "simulator: Driving simulator tests",
            "analytics: Data analytics tests",
            "performance: Performance tests",
            "real_time: Real-time processing tests"
        ]
        
        for marker in expected_markers:
            assert marker in markers_text, f"Missing marker: {marker}"
    
    def test_filter_warnings_configuration(self, config):
        """Test filterwarnings configuration."""
        section = config["tool:pytest"]
        assert "filterwarnings" in section, "filterwarnings should be configured"
        
        warnings = section["filterwarnings"]
        assert "ignore::UserWarning" in warnings, "UserWarning should be ignored"
        assert "ignore::DeprecationWarning" in warnings, "DeprecationWarning should be ignored"
    
    @pytest.mark.parametrize("marker_name,description", [
        ("unit", "Unit tests"),
        ("integration", "Integration tests"),
        ("database", "Database tests"),
        ("slow", "Slow running tests"),
        ("simulator", "Driving simulator tests"),
        ("analytics", "Data analytics tests"),
        ("performance", "Performance tests"),
        ("real_time", "Real-time processing tests"),
    ])
    def test_individual_markers(self, config, marker_name, description):
        """Test individual marker definitions."""
        section = config["tool:pytest"]
        markers_text = section["markers"]
        expected_marker = f"{marker_name}: {description}"
        assert expected_marker in markers_text, f"Marker '{marker_name}' not properly defined"
    
    def test_config_file_syntax(self, config_file_path):
        """Test that pytest.ini has valid INI syntax."""
        try:
            config = configparser.ConfigParser()
            config.read(config_file_path)
        except configparser.Error as e:
            pytest.fail(f"Invalid INI syntax in pytest.ini: {e}")
    
    def test_no_duplicate_sections(self, config):
        """Test that there are no duplicate sections."""
        sections = config.sections()
        assert len(sections) == len(set(sections)), "Duplicate sections found in pytest.ini"
    
    def test_required_directories_structure(self):
        """Test that required directories exist or can be created."""
        base_path = Path(__file__).parent
        tests_dir = base_path / "tests"
        src_dir = base_path / "src"
        
        # Tests directory should exist for testpaths
        if not tests_dir.exists():
            pytest.skip("tests directory doesn't exist - create it for proper pytest operation")
        
        # Src directory should exist for coverage
        if not src_dir.exists():
            pytest.skip("src directory doesn't exist - create it for coverage to work")


class TestPytestConfigurationIntegration:
    """Integration tests for pytest configuration."""
    
    def test_pytest_can_parse_config(self):
        """Test that pytest can successfully parse the configuration."""
        import subprocess
        import sys
        
        try:
            result = subprocess.run(
                [sys.executable, "-m", "pytest", "--collect-only", "--quiet"],
                capture_output=True,
                text=True,
                cwd=Path(__file__).parent
            )
            # Should not fail due to configuration errors
            assert result.returncode != 3, f"pytest config error: {result.stderr}"
        except FileNotFoundError:
            pytest.skip("pytest not installed")
    
    def test_markers_are_recognized(self):
        """Test that custom markers are recognized by pytest."""
        import subprocess
        import sys
        
        try:
            result = subprocess.run(
                [sys.executable, "-m", "pytest", "--markers"],
                capture_output=True,
                text=True,
                cwd=Path(__file__).parent
            )
            
            if result.returncode == 0:
                output = result.stdout
                markers = ["unit", "integration", "database", "slow", "simulator", 
                          "analytics", "performance", "real_time"]
                
                for marker in markers:
                    assert marker in output, f"Marker '{marker}' not recognized by pytest"
        except FileNotFoundError:
            pytest.skip("pytest not installed")


@pytest.mark.slow
class TestPytestConfigurationPerformance:
    """Performance tests for pytest configuration."""
    
    def test_config_loading_performance(self, config_file_path):
        """Test that configuration loads quickly."""
        import time
        
        start_time = time.time()
        config = configparser.ConfigParser()
        config.read(config_file_path)
        end_time = time.time()
        
        load_time = end_time - start_time
        assert load_time < 0.1, f"Configuration loading too slow: {load_time}s"


# Utility functions for testing
def validate_pytest_config(config_path: Path) -> dict:
    """Utility function to validate pytest configuration and return issues."""
    issues = []
    
    if not config_path.exists():
        issues.append("pytest.ini file not found")
        return {"valid": False, "issues": issues}
    
    try:
        config = configparser.ConfigParser()
        config.read(config_path)
        
        if "tool:pytest" not in config.sections():
            issues.append("Missing [tool:pytest] section")
        
        # Add more validation logic here
        
    except Exception as e:
        issues.append(f"Configuration parsing error: {e}")
    
    return {"valid": len(issues) == 0, "issues": issues}


if __name__ == "__main__":
    # Run basic validation when script is executed directly
    config_path = Path(__file__).parent / "pytest.ini"
    result = validate_pytest_config(config_path)
    
    if result["valid"]:
        print("✅ pytest.ini configuration is valid")
    else:
        print("❌ Issues found in pytest.ini:")
        for issue in result["issues"]:
            print(f"  - {issue}")